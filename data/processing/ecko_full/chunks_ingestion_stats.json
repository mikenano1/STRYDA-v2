{
  "chunks_processed": 204,
  "chunks_inserted": 184,
  "chunks_skipped": 20,
  "embeddings_generated": 184,
  "errors": [
    "Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens, however you requested 10010 tokens (10010 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
  ]
}